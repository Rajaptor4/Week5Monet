{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"sourceType":"competition"}],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport tensorflow as keras\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom zipfile import ZipFile\nfrom tensorflow.keras import layers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monet_tfrec_pattern = \"/kaggle/input/gan-getting-started/monet_tfrec/*.tfrec\"\nphoto_tfrec_pattern = \"/kaggle/input/gan-getting-started/photo_tfrec/*.tfrec\"\n\nmonet_files = tf.data.Dataset.list_files(monet_tfrec_pattern)\nphoto_files = tf.data.Dataset.list_files(photo_tfrec_pattern)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_tfrecord(tfrecord):\n    feature_description = {'image': tf.io.FixedLenFeature([], tf.string)}\n    return tf.io.parse_single_example(tfrecord, feature_description)\n\ndef preprocess_image(features):\n    image = tf.image.decode_jpeg(features['image'], channels=3)\n    image = tf.image.resize(image, [256, 256])  # Resize to 256x256\n    image = (image / 127.5) - 1  # Normalize the images to [-1, 1]\n    return image\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_image(features):\n    image = tf.image.decode_jpeg(features['image'], channels=3)\n    image = tf.image.resize(image, [32, 32])  \n    image = (image / 127.5) - 1  \n    return image\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 32\n\nmonet_dataset = monet_files.interleave(\n    lambda x: tf.data.TFRecordDataset(x).map(parse_tfrecord),\n    num_parallel_calls=tf.data.AUTOTUNE).map(preprocess_image).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\nphoto_dataset = photo_files.interleave(\n    lambda x: tf.data.TFRecordDataset(x).map(parse_tfrecord),\n    num_parallel_calls=tf.data.AUTOTUNE).map(preprocess_image).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_images(dataset, title):\n    plt.figure(figsize=(12, 12))\n    for images in dataset.take(1):\n        for i in range(9):\n            ax = plt.subplot(3, 3, i + 1)\n            plt.imshow((images[i] + 1) / 2)  \n            plt.title(title)\n            plt.axis('off')\n    plt.show()\n\nshow_images(monet_dataset, \"Monet Paintings\")\n\nshow_images(photo_dataset, \"Photos\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_generator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(16*16*256, use_bias=False, input_shape=(100,)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Reshape((16, 16, 256)))\n\n    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n\n    return model\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef make_discriminator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[256, 256, 3]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n    return model\n\ngenerator = make_generator_model()\ndiscriminator = make_discriminator_model()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\ndef discriminator_loss(real_output, fake_output):\n    pass  \n\ndef generator_loss(fake_output):\n    pass  \n\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noise_dim = 100\nEPOCHS = 50  \n\n@tf.function\ndef train_step(images):\n    pass  \n\ndef train(dataset, epochs):\n    for epoch in range(epochs):\n        for image_batch in dataset:\n            train_step(image_batch)\n\ntrain(monet_dataset, EPOCHS)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_and_save_images(model, num_examples_to_generate, output_dir):\n    noise = tf.random.normal([num_examples_to_generate, 100])\n\n    generated_images = model(noise, training=False)\n\n    generated_images = (generated_images + 1) / 2\n\n    os.makedirs(output_dir, exist_ok=True)\n\n    for i in range(num_examples_to_generate):\n        img = tf.keras.preprocessing.image.array_to_img(generated_images[i])\n        img.save(os.path.join(output_dir, f'generated_image_{i:04d}.png'))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_folder = '/path/to/save/images'  \n\ngenerate_and_save_images(generator, 100, output_folder)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Average Color Distribution in Monet Paintings and in Test Photos**","metadata":{}},{"cell_type":"code","source":"def plot_color_distribution(dataset, title):\n    colors = np.array([0, 0, 0], dtype=np.float32)\n    total_images = 0\n\n    for images in dataset.take(10):  \n        for img in images:\n            img = (img + 1) / 2  \n            colors += img.numpy().sum(axis=(0, 1))\n            total_images += 1\n\n    colors /= (total_images * 256 * 256)  \n    plt.bar(['Red', 'Green', 'Blue'], colors)\n    plt.title(f'Average Color Distribution in {title}')\n    plt.show()\n\nplot_color_distribution(monet_dataset, \"Monet Paintings\")\nplot_color_distribution(photo_dataset, \"Other Photos\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_intensity_histogram(dataset, title):\n    plt.figure(figsize=(10, 4))\n    for images in dataset.take(1):  \n        for i in range(3):  \n            channel = images[..., i].numpy().flatten()\n            sns.histplot(channel, color=['r', 'g', 'b'][i], alpha=0.5, bins=50)\n    plt.title(f'Pixel Intensity Distribution in {title}')\n    plt.show()\n\nplot_intensity_histogram(monet_dataset, \"Monet Paintings\")\nplot_intensity_histogram(photo_dataset, \"Other Photos\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images(monet_dataset, \"Sample Monet Paintings\")\nshow_images(photo_dataset, \"Sample Photos\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **CycleGAN**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\n\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n    \nprint(tf.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CycleGAN_PATH = KaggleDatasets().get_gcs_path()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MONET_FILE = tf.io.gfile.glob(str(CycleGAN_PATH + '/monet_tfrec/*.tfrec'))\nprint('Monet TFRecord Files:', len(MONET_FILE))\n\nPHOTO_FILENAMES = tf.io.gfile.glob(str(CycleGAN_PATH + '/photo_tfrec/*.tfrec'))\nprint('Photo TFRecord Files:', len(PHOTO_FILENAMES))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = [256, 256]\n\ndef decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = (tf.cast(image, tf.float32) / 127.5) - 1\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\ndef read_tfrecord(example):\n    tfrecord_format = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dataset(filenames, labeled=True, ordered=False):\n    dataset = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monet_ds = load_dataset(MONET_FILE, labeled=True).batch(1)\nphoto_ds = load_dataset(PHOTO_FILENAMES, labeled=True).batch(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_monet = next(iter(monet_ds))\nsample_photo = next(iter(photo_ds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplot(121)\nplt.title('Photo')\nplt.imshow(sample_photo[0] * 0.5 + 0.5)\n\nplt.subplot(122)\nplt.title('Monet')\nplt.imshow(sample_monet[0] * 0.5 + 0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now I will be building the generator**","metadata":{}},{"cell_type":"code","source":"OUTPUT_CHANNELS = 3\n\ndef downsample(filters, size, apply_instancenorm=True):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n    result = keras.Sequential()\n    result.add(layers.Conv2D(filters, size, strides=2, padding='same',\n                             kernel_initializer=initializer, use_bias=False))\n\n    if apply_instancenorm:\n        result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n\n    result.add(layers.LeakyReLU())\n\n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def upsample(filters, size, apply_dropout=False):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n    result = keras.Sequential()\n    result.add(layers.Conv2DTranspose(filters, size, strides=2,\n                                      padding='same',\n                                      kernel_initializer=initializer,\n                                      use_bias=False))\n\n    result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n\n    if apply_dropout:\n        result.add(layers.Dropout(0.5))\n\n    result.add(layers.ReLU())\n\n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generator_model():\n    inputs = layers.Input(shape=[256, 256, 3])\n\n    down_stack = [\n        downsample(64, 4, apply_instancenorm=False), \n        downsample(128, 4),  \n        downsample(256, 4),  \n        downsample(512, 4),  \n        downsample(512, 4),  \n        downsample(512, 4),  \n        downsample(512, 4),  \n        downsample(512, 4),  \n    ]\n\n    up_stack = [\n        upsample(512, 4, apply_dropout=True),  \n        upsample(512, 4, apply_dropout=True),  \n        upsample(512, 4, apply_dropout=True),  \n        upsample(512, 4),  \n        upsample(256, 4),  \n        upsample(128, 4),  \n        upsample(64, 4),  \n    ]\n\n    initializer = tf.random_normal_initializer(0., 0.02)\n    last = layers.Conv2DTranspose(OUTPUT_CHANNELS, 4, strides=2, padding='same',\n                                  kernel_initializer=initializer, activation='tanh') \n\n    x = inputs\n\n    skips = []\n    for down in down_stack:\n        x = down(x)\n        skips.append(x)\n\n    skips = reversed(skips[:-1])\n\n    for up, skip in zip(up_stack, skips):\n        x = up(x)\n        x = layers.Concatenate()([x, skip])\n\n    x = last(x)\n\n    return keras.Model(inputs=inputs, outputs=x)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_discriminator():\n    inputs = layers.Input(shape=[256, 256, 3], name='input_image')\n\n    # Downsampling\n    down_stack = [\n        downsample(64, 4, apply_instancenorm=False),  \n        downsample(128, 4), \n        downsample(256, 4),  \n    ]\n\n    zero_pad1 = layers.ZeroPadding2D()(down_stack[-1]) \n    conv = layers.Conv2D(512, 4, strides=1,\n                         kernel_initializer=initializer,\n                         use_bias=False)(zero_pad1)  \n\n    norm1 = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)(conv)\n    leaky_relu = layers.LeakyReLU()(norm1)\n\n    zero_pad2 = layers.ZeroPadding2D()(leaky_relu)  \n\n    last = layers.Conv2D(1, 4, strides=1,\n                         kernel_initializer=initializer)(zero_pad2) \n\n    return tf.keras.Model(inputs=inputs, outputs=last)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    monet_gen = generator_model() \n    photo_gen = generator_model()\n\n    monet_dis = generator_model()\n    photo_dis = generator_model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_monet = monet_gen(sample_photo)\n\nplt.subplot(1, 2, 1)\nplt.title(\"Original Photo\")\nplt.imshow(sample_photo[0] * 0.5 + 0.5)\n\nplt.subplot(1, 2, 2)\nplt.title(\"Monet-esque Photo\")\nplt.imshow(to_monet[0] * 0.5 + 0.5)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CycleGanModel(keras.Model):\n    def __init__(self, monet_gen, photo_gen, monet_disc, photo_disc, lambda_cycle=10):\n        super(CycleGanModel, self).__init__()\n        self.monet_gen = monet_gen\n        self.photo_gen = photo_gen\n        self.monet_disc = monet_disc\n        self.photo_disc = photo_disc\n        self.lambda_cycle = lambda_cycle\n\n    def compile(self, monet_gen_opt, photo_gen_opt, monet_disc_opt, photo_disc_opt, gen_loss, disc_loss, cycle_loss, identity_loss):\n        super(CycleGanModel, self).compile()\n        self.m_gen_opt = monet_gen_opt\n        self.p_gen_opt = photo_gen_opt\n        self.m_disc_opt = monet_disc_opt\n        self.p_disc_opt = photo_disc_opt\n        self.gen_loss = gen_loss\n        self.disc_loss = disc_loss\n        self.cycle_loss = cycle_loss\n        self.identity_loss = identity_loss\n\n    def train_step(self, data):\n        real_monet, real_photo = data\n\n        with tf.GradientTape(persistent=True) as tape:\n            fake_monet = self.monet_gen(real_photo, training=True)\n            fake_photo = self.photo_gen(real_monet, training=True)\n            cycled_monet = self.monet_gen(fake_photo, training=True)\n            cycled_photo = self.photo_gen(fake_monet, training=True)\n\n            same_monet = self.monet_gen(real_monet, training=True)\n            same_photo = self.photo_gen(real_photo, training=True)\n\n            disc_real_monet = self.monet_disc(real_monet, training=True)\n            disc_real_photo = self.photo_disc(real_photo, training=True)\n            disc_fake_monet = self.monet_disc(fake_monet, training=True)\n            disc_fake_photo = self.photo_disc(fake_photo, training=True)\n\n            monet_gen_loss = self.gen_loss(disc_fake_monet)\n            photo_gen_loss = self.gen_loss(disc_fake_photo)\n            monet_disc_loss = self.disc_loss(disc_real_monet, disc_fake_monet)\n            photo_disc_loss = self.disc_loss(disc_real_photo, disc_fake_photo)\n            total_cycle_loss = self.cycle_loss(real_monet, cycled_monet, self.lambda_cycle) + self.cycle_loss(real_photo, cycled_photo, self.lambda_cycle)\n\n            total_monet_gen_loss = monet_gen_loss + total_cycle_loss + self.identity_loss(real_monet, same_monet, self.lambda_cycle)\n            total_photo_gen_loss = photo_gen_loss + total_cycle_loss + self.identity_loss(real_photo, same_photo, self.lambda_cycle)\n\n        monet_gen_grads = tape.gradient(total_monet_gen_loss, self.monet_gen.trainable_variables)\n        photo_gen_grads = tape.gradient(total_photo_gen_loss, self.photo_gen.trainable_variables)\n        monet_disc_grads = tape.gradient(monet_disc_loss, self.monet_disc.trainable_variables)\n        photo_disc_grads = tape.gradient(photo_disc_loss, self.photo_disc.trainable_variables)\n\n        self.m_gen_opt.apply_gradients(zip(monet_gen_grads, self.monet_gen.trainable_variables))\n        self.p_gen_opt.apply_gradients(zip(photo_gen_grads, self.photo_gen.trainable_variables))\n        self.m_disc_opt.apply_gradients(zip(monet_disc_grads, self.monet_disc.trainable_variables))\n        self.p_disc_opt.apply_gradients(zip(photo_disc_grads, self.photo_disc.trainable_variables))\n\n        return {\n            \"monet_gen_loss\": total_monet_gen_loss,\n            \"photo_gen_loss\": total_photo_gen_loss,\n            \"monet_disc_loss\": monet_disc_loss,\n            \"photo_disc_loss\": photo_disc_loss\n        }\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    def calc_discriminator_loss(real_output, fake_output):\n        real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(real_output), real_output)\n\n        fake_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(fake_output), fake_output)\n\n        total_loss = (real_loss + fake_loss) / 2\n        return total_loss\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    def calc_generator_loss(fake_output):\n        return tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(fake_output), fake_output)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    def calculate_cycle_consistency_loss(original_image, cycled_image, lambda_value):\n        cycle_loss = tf.reduce_mean(tf.abs(original_image - cycled_image))\n\n        return lambda_value * cycle_loss\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    def calculate_identity_loss(original_image, reconstructed_image, lambda_value):\n        identity_loss = tf.reduce_mean(tf.abs(original_image - reconstructed_image))\n\n        return lambda_value * 0.5 * identity_loss\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    learning_rate = 2e-4\n    beta = 0.5\n\n    monet_gen_optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=beta)\n    photo_gen_optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=beta)\n    monet_disc_optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=beta)\n    photo_disc_optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=beta)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    cycle_gan = CycleGanModel(monet_gen, photo_gen, monet_dis, photo_dis)\n\n    cycle_gan.compile(\n        monet_gen_opt=monet_gen_optimizer,\n        photo_gen_opt=photo_gen_optimizer,\n        monet_disc_opt=monet_disc_optimizer,\n        photo_disc_opt=photo_disc_optimizer,\n        gen_loss=calc_generator_loss,\n        disc_loss=calc_discriminator_loss,\n        cycle_loss=calculate_cycle_consistency_loss,\n        identity_loss=calculate_identity_loss\n    )\n\n    cycle_gan.fit(\n        tf.data.Dataset.zip((monet_ds, photo_ds)),\n        epochs=5\n    )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(5, 2, figsize=(12, 12))\n\nfor i, img in enumerate(photo_ds.take(5)):\n    monet_style_img = monet_gen(img, training=False)[0].numpy()\n    monet_style_img = ((monet_style_img * 127.5) + 127.5).astype(np.uint8)\n\n    input_img = ((img[0] * 127.5) + 127.5).numpy().astype(np.uint8)\n\n    axes[i, 0].imshow(input_img)\n    axes[i, 1].imshow(monet_style_img)\n\n    axes[i, 0].set_title(\"Input Photo\")\n    axes[i, 1].set_title(\"Monet-esque\")\n    axes[i, 0].axis(\"off\")\n    axes[i, 1].axis(\"off\")\n\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import PIL\nimport shutil\nimport os\n\nimage_dir = \"../image\"\n\nif not os.path.exists(image_dir):\n    os.makedirs(image_dir)\nelse:\n    print(f\"Directory '{image_dir}' already exists.\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import PIL.Image\nimport os\n\noutput_folder = \"../images\"\nos.makedirs(output_folder, exist_ok=True)  \n\nfor i, img in enumerate(photo_ds, start=1):\n    monet_style_img = monet_gen(img, training=False)[0].numpy()\n    monet_style_img = ((monet_style_img * 127.5) + 127.5).astype(np.uint8)\n    image = PIL.Image.fromarray(monet_style_img)\n    image.save(os.path.join(output_folder, f\"{i}.jpg\"))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/images\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}